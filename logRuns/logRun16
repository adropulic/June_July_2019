
Processing TMVAAnalysis.C...
<HEADER> DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree efficiencyTree of type Signal with 59472 events
<HEADER> DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree efficiencyTree of type Background with 240000 events
going to methods
<HEADER> Factory                  : Booking method: BDT
                         : 
<HEADER> DataSetFactory           : [dataset] : Number of events in input trees
                         : Dataset[dataset] :     Signal     requirement: "l1Pt_1 > 0 && l1Pt_2 > 0 && l1Mass > 0"
                         : Dataset[dataset] :     Signal          -- number of events passed: 30977  / sum of weights: 30977
                         : Dataset[dataset] :     Signal          -- efficiency             : 0.520867
                         : Dataset[dataset] :     Background requirement: "l1Pt_1 > 0 && l1Pt_2 > 0 && l1Mass > 0"
                         : Dataset[dataset] :     Background      -- number of events passed: 3377   / sum of weights: 3377 
                         : Dataset[dataset] :     Background      -- efficiency             : 0.0140708
                         : Dataset[dataset] :  you have opted for interpreting the requested number of training/testing events
                         :  to be the number of events AFTER your preselection cuts
                         : 
                         : Dataset[dataset] :  you have opted for interpreting the requested number of training/testing events
                         :  to be the number of events AFTER your preselection cuts
                         : 
                         : Dataset[dataset] : Weight renormalisation mode: "EqualNumEvents": renormalises all event classes ...
                         : Dataset[dataset] :  such that the effective (weighted) number of events in each class is the same 
                         : Dataset[dataset] :  (and equals the number of events (entries) given for class=0 )
                         : Dataset[dataset] : ... i.e. such that Sum[i=1..N_j]{w_i} = N_classA, j=classA, classB, ...
                         : Dataset[dataset] : ... (note that N_j is the sum of TRAINING events
                         : Dataset[dataset] :  ..... Testing events are not renormalised nor included in the renormalisation factor!)
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 15488
                         : Signal     -- testing events             : 15488
                         : Signal     -- training and testing events: 30976
                         : Dataset[dataset] : Signal     -- due to the preselection a scaling factor has been applied to the numbers of requested events: 0.520867
                         : Background -- training events            : 1688
                         : Background -- testing events             : 1688
                         : Background -- training and testing events: 3376
                         : Dataset[dataset] : Background -- due to the preselection a scaling factor has been applied to the numbers of requested events: 0.0140708
                         : 
<HEADER> DataSetInfo              : Correlation matrix (Signal):
                         : ---------------------------------------------------------
                         :              l1Pt_1  l1Pt_2 l1DeltaEta l1DeltaPhi  l1Mass
                         :     l1Pt_1:  +1.000  +0.682     -0.004     -0.015  +0.360
                         :     l1Pt_2:  +0.682  +1.000     -0.002     -0.008  +0.377
                         : l1DeltaEta:  -0.004  -0.002     +1.000     +0.003  -0.016
                         : l1DeltaPhi:  -0.015  -0.008     +0.003     +1.000  -0.008
                         :     l1Mass:  +0.360  +0.377     -0.016     -0.008  +1.000
                         : ---------------------------------------------------------
<HEADER> DataSetInfo              : Correlation matrix (Background):
                         : ---------------------------------------------------------
                         :              l1Pt_1  l1Pt_2 l1DeltaEta l1DeltaPhi  l1Mass
                         :     l1Pt_1:  +1.000  +0.567     +0.001     +0.028  +0.248
                         :     l1Pt_2:  +0.567  +1.000     -0.031     +0.009  +0.276
                         : l1DeltaEta:  +0.001  -0.031     +1.000     +0.035  -0.048
                         : l1DeltaPhi:  +0.028  +0.009     +0.035     +1.000  -0.038
                         :     l1Mass:  +0.248  +0.276     -0.048     -0.038  +1.000
                         : ---------------------------------------------------------
<HEADER> DataSetFactory           : [dataset] :  
                         : 
<HEADER> Factory                  : Booking method: MLP_1
                         : 
<HEADER> MLP_1                    : [dataset] : Create Transformation "N" with events from all classes.
                         : 
<HEADER>                          : Transformation, Variable selection : 
                         : Input : variable 'l1Pt_1' <---> Output : variable 'l1Pt_1'
                         : Input : variable 'l1Pt_2' <---> Output : variable 'l1Pt_2'
                         : Input : variable 'l1DeltaEta' <---> Output : variable 'l1DeltaEta'
                         : Input : variable 'l1DeltaPhi' <---> Output : variable 'l1DeltaPhi'
                         : Input : variable 'l1Mass' <---> Output : variable 'l1Mass'
<HEADER> MLP_1                    : Building Network. 
                         : Initializing weights
<HEADER> Factory                  : Booking method: MLP_2
                         : 
<HEADER> MLP_2                    : [dataset] : Create Transformation "N" with events from all classes.
                         : 
<HEADER>                          : Transformation, Variable selection : 
                         : Input : variable 'l1Pt_1' <---> Output : variable 'l1Pt_1'
                         : Input : variable 'l1Pt_2' <---> Output : variable 'l1Pt_2'
                         : Input : variable 'l1DeltaEta' <---> Output : variable 'l1DeltaEta'
                         : Input : variable 'l1DeltaPhi' <---> Output : variable 'l1DeltaPhi'
                         : Input : variable 'l1Mass' <---> Output : variable 'l1Mass'
<HEADER> MLP_2                    : Building Network. 
                         : Initializing weights
<HEADER> Factory                  : Booking method: MLP_3
                         : 
<HEADER> MLP_3                    : [dataset] : Create Transformation "Decorrelate" with events from all classes.
                         : 
<HEADER>                          : Transformation, Variable selection : 
                         : Input : variable 'l1Pt_1' <---> Output : variable 'l1Pt_1'
                         : Input : variable 'l1Pt_2' <---> Output : variable 'l1Pt_2'
                         : Input : variable 'l1DeltaEta' <---> Output : variable 'l1DeltaEta'
                         : Input : variable 'l1DeltaPhi' <---> Output : variable 'l1DeltaPhi'
                         : Input : variable 'l1Mass' <---> Output : variable 'l1Mass'
<HEADER> MLP_3                    : Building Network. 
                         : Initializing weights
entered DNN
!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Layout=TANH|100,TANH|50,TANH|10,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0.
<HEADER> Factory                  : Booking method: DNN
                         : 
<VERBOSE>                          : Parsing option string: 
<VERBOSE>                          : ... "!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Layout=TANH|100,TANH|50,TANH|10,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0."
<VERBOSE>                          : The following options are set:
<VERBOSE>                          : - By User:
<VERBOSE>                          :     <none>
<VERBOSE>                          : - Default:
<VERBOSE>                          :     Boost_num: "0" [Number of times the classifier will be boosted]
<VERBOSE>                          : Parsing option string: 
<VERBOSE>                          : ... "!H:V:ErrorStrategy=CROSSENTROPY:VarTransform=G:WeightInitialization=XAVIERUNIFORM:Layout=TANH|100,TANH|50,TANH|10,LINEAR:TrainingStrategy=LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0."
<VERBOSE>                          : The following options are set:
<VERBOSE>                          : - By User:
<VERBOSE>                          :     V: "True" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
<VERBOSE>                          :     VarTransform: "G" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
<VERBOSE>                          :     H: "False" [Print method-specific help message]
<VERBOSE>                          :     Layout: "TANH|100,TANH|50,TANH|10,LINEAR" [Layout of the network.]
<VERBOSE>                          :     ErrorStrategy: "CROSSENTROPY" [Loss function: Mean squared error (regression) or cross entropy (binary classification).]
<VERBOSE>                          :     WeightInitialization: "XAVIERUNIFORM" [Weight initialization strategy]
<VERBOSE>                          :     TrainingStrategy: "LearningRate=1e-3,Momentum=0.9,Repetitions=1,ConvergenceSteps=10,BatchSize=128,TestRepetitions=1,MaxEpochs=30,WeightDecay=1e-4,Regularization=None,Optimizer=ADAM,DropConfig=0.0+0.0+0.0+0." [Defines the training strategies.]
<VERBOSE>                          : - Default:
<VERBOSE>                          :     VerbosityLevel: "Default" [Verbosity level]
<VERBOSE>                          :     CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
<VERBOSE>                          :     IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
<VERBOSE>                          :     ValidationSize: "20%" [Part of the training data to use for validation. Specify as 0.2 or 20% to use a fifth of the data set as validation set. Specify as 100 to use exactly 100 events. (Default: 20%)]
<VERBOSE>                          :     Architecture: "CPU" [Which architecture to perform the training on.]
<HEADER> DNN                      : [dataset] : Create Transformation "G" with events from all classes.
                         : 
<HEADER>                          : Transformation, Variable selection : 
                         : Input : variable 'l1Pt_1' <---> Output : variable 'l1Pt_1'
                         : Input : variable 'l1Pt_2' <---> Output : variable 'l1Pt_2'
                         : Input : variable 'l1DeltaEta' <---> Output : variable 'l1DeltaEta'
                         : Input : variable 'l1DeltaPhi' <---> Output : variable 'l1DeltaPhi'
                         : Input : variable 'l1Mass' <---> Output : variable 'l1Mass'
                         : Preparing the Gaussian transformation...
<HEADER> TFHandler_DNN            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    0.021833     0.99882   [     -3.2357      5.4200 ]
                         :     l1Pt_2:   -0.012797      1.0083   [     -5.1237      5.7307 ]
                         : l1DeltaEta:  -0.0092430     0.92525   [     -5.2663      5.7307 ]
                         : l1DeltaPhi:  -0.0038107     0.99734   [     -3.5687      5.7307 ]
                         :     l1Mass:    0.019930      1.0026   [     -5.7307      5.7307 ]
                         : ---------------------------------------------------------------------
<HEADER> Factory                  : Train all methods
<HEADER> Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
<HEADER>                          : Transformation, Variable selection : 
                         : Input : variable 'l1Pt_1' <---> Output : variable 'l1Pt_1'
                         : Input : variable 'l1Pt_2' <---> Output : variable 'l1Pt_2'
                         : Input : variable 'l1DeltaEta' <---> Output : variable 'l1DeltaEta'
                         : Input : variable 'l1DeltaPhi' <---> Output : variable 'l1DeltaPhi'
                         : Input : variable 'l1Mass' <---> Output : variable 'l1Mass'
<HEADER> TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:      56.510      48.910   [      5.5000      511.50 ]
                         :     l1Pt_2:      39.905      33.110   [      5.5000      511.50 ]
                         : l1DeltaEta:    0.044697      3.0366   [     -8.5800      8.9400 ]
                         : l1DeltaPhi:    0.063985      2.8892   [     -6.1912      6.1040 ]
                         :     l1Mass:      247.60      354.33   [  7.7601e-07      5373.8 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
<HEADER> IdTransformation         : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : l1Pt_1     : 3.795e-01
                         :    2 : l1Pt_2     : 2.505e-01
                         :    3 : l1Mass     : 1.557e-01
                         :    4 : l1DeltaPhi : 4.885e-02
                         :    5 : l1DeltaEta : 4.104e-02
                         : -----------------------------------
<HEADER> Factory                  : Train method: BDT for Classification
                         : 
<HEADER> BDT                      : #events: (reweighted) sig: 8588 bkg: 8588
                         : #events: (unweighted) sig: 15488 bkg: 1688
                         : Training 800 Decision Trees ... patience please
                         : Elapsed time for training with 17176 events: 5.19 sec         
<HEADER> BDT                      : [dataset] : Evaluation of BDT on training sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 1.38 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_BDT.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_BDT.class.C
                         : TMVA_output.root:/dataset/Method_BDT/BDT
<HEADER> Factory                  : Training finished
                         : 
<HEADER> Factory                  : Train method: MLP_1 for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ MLP_1 ] :
                         : 
                         : --- Short description:
                         : 
                         : The MLP artificial neural network (ANN) is a traditional feed-
                         : forward multilayer perceptron implementation. The MLP has a user-
                         : defined hidden layer architecture, while the number of input (output)
                         : nodes is determined by the input variables (output classes, i.e., 
                         : signal and one background). 
                         : 
                         : --- Performance optimisation:
                         : 
                         : Neural networks are stable and performing for a large variety of 
                         : linear and non-linear classification problems. However, in contrast
                         : to (e.g.) boosted decision trees, the user is advised to reduce the 
                         : number of input variables that have only little discrimination power. 
                         : 
                         : In the tests we have carried out so far, the MLP and ROOT networks
                         : (TMlpANN, interfaced via TMVA) performed equally well, with however
                         : a clear speed advantage for the MLP. The Clermont-Ferrand neural 
                         : net (CFMlpANN) exhibited worse classification performance in these
                         : tests, which is partly due to the slow convergence of its training
                         : (at least 10k training cycles are required to achieve approximately
                         : competitive results).
                         : 
                         : Overtraining: only the TMlpANN performs an explicit separation of the
                         : full training sample into independent training and validation samples.
                         : We have found that in most high-energy physics applications the 
                         : available degrees of freedom (training events) are sufficient to 
                         : constrain the weights of the relatively simple architectures required
                         : to achieve good performance. Hence no overtraining should occur, and 
                         : the use of validation samples would only reduce the available training
                         : information. However, if the performance on the training sample is 
                         : found to be significantly better than the one found with the inde-
                         : pendent test sample, caution is needed. The results for these samples 
                         : are printed to standard output at the end of each training job.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : The hidden layer architecture for all ANNs is defined by the option
                         : "HiddenLayers=N+1,N,...", where here the first hidden layer has N+1
                         : neurons and the second N neurons (and so on), and where N is the number  
                         : of input variables. Excessive numbers of hidden layers should be avoided,
                         : in favour of more neurons in the first hidden layer.
                         : 
                         : The number of cycles should be above 500. As said, if the number of
                         : adjustable weights is small compared to the training sample size,
                         : using a large number of training samples should not lead to overtraining.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
<HEADER> TFHandler_MLP_1          :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    -0.79838     0.19332   [     -1.0000      1.0000 ]
                         :     l1Pt_2:    -0.86401     0.13087   [     -1.0000      1.0000 ]
                         : l1DeltaEta:   -0.015446     0.34664   [     -1.0000      1.0000 ]
                         : l1DeltaPhi:    0.017500     0.46998   [     -1.0000      1.0000 ]
                         :     l1Mass:    -0.90785     0.13187   [     -1.0000      1.0000 ]
                         : ---------------------------------------------------------------------
                         : Training Network
                         : 
                         : Inaccurate progress timing for MLP... 
                         : Elapsed time for training with 17176 events: 4.55 sec         
<HEADER> MLP_1                    : [dataset] : Evaluation of MLP_1 on training sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 0.0319 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_MLP_1.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_MLP_1.class.C
                         : Write special histos to file: TMVA_output.root:/dataset/Method_MLP_1/MLP_1
<HEADER> Factory                  : Training finished
                         : 
<HEADER> Factory                  : Train method: MLP_2 for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ MLP_2 ] :
                         : 
                         : --- Short description:
                         : 
                         : The MLP artificial neural network (ANN) is a traditional feed-
                         : forward multilayer perceptron implementation. The MLP has a user-
                         : defined hidden layer architecture, while the number of input (output)
                         : nodes is determined by the input variables (output classes, i.e., 
                         : signal and one background). 
                         : 
                         : --- Performance optimisation:
                         : 
                         : Neural networks are stable and performing for a large variety of 
                         : linear and non-linear classification problems. However, in contrast
                         : to (e.g.) boosted decision trees, the user is advised to reduce the 
                         : number of input variables that have only little discrimination power. 
                         : 
                         : In the tests we have carried out so far, the MLP and ROOT networks
                         : (TMlpANN, interfaced via TMVA) performed equally well, with however
                         : a clear speed advantage for the MLP. The Clermont-Ferrand neural 
                         : net (CFMlpANN) exhibited worse classification performance in these
                         : tests, which is partly due to the slow convergence of its training
                         : (at least 10k training cycles are required to achieve approximately
                         : competitive results).
                         : 
                         : Overtraining: only the TMlpANN performs an explicit separation of the
                         : full training sample into independent training and validation samples.
                         : We have found that in most high-energy physics applications the 
                         : available degrees of freedom (training events) are sufficient to 
                         : constrain the weights of the relatively simple architectures required
                         : to achieve good performance. Hence no overtraining should occur, and 
                         : the use of validation samples would only reduce the available training
                         : information. However, if the performance on the training sample is 
                         : found to be significantly better than the one found with the inde-
                         : pendent test sample, caution is needed. The results for these samples 
                         : are printed to standard output at the end of each training job.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : The hidden layer architecture for all ANNs is defined by the option
                         : "HiddenLayers=N+1,N,...", where here the first hidden layer has N+1
                         : neurons and the second N neurons (and so on), and where N is the number  
                         : of input variables. Excessive numbers of hidden layers should be avoided,
                         : in favour of more neurons in the first hidden layer.
                         : 
                         : The number of cycles should be above 500. As said, if the number of
                         : adjustable weights is small compared to the training sample size,
                         : using a large number of training samples should not lead to overtraining.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
<HEADER> TFHandler_MLP_2          :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    -0.79838     0.19332   [     -1.0000      1.0000 ]
                         :     l1Pt_2:    -0.86401     0.13087   [     -1.0000      1.0000 ]
                         : l1DeltaEta:   -0.015446     0.34664   [     -1.0000      1.0000 ]
                         : l1DeltaPhi:    0.017500     0.46998   [     -1.0000      1.0000 ]
                         :     l1Mass:    -0.90785     0.13187   [     -1.0000      1.0000 ]
                         : ---------------------------------------------------------------------
                         : Training Network
                         : 
                         : Elapsed time for training with 17176 events: 49.7 sec         
<HEADER> MLP_2                    : [dataset] : Evaluation of MLP_2 on training sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 0.0318 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_MLP_2.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_MLP_2.class.C
                         : Write special histos to file: TMVA_output.root:/dataset/Method_MLP_2/MLP_2
<HEADER> Factory                  : Training finished
                         : 
<HEADER> Factory                  : Train method: MLP_3 for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ MLP_3 ] :
                         : 
                         : --- Short description:
                         : 
                         : The MLP artificial neural network (ANN) is a traditional feed-
                         : forward multilayer perceptron implementation. The MLP has a user-
                         : defined hidden layer architecture, while the number of input (output)
                         : nodes is determined by the input variables (output classes, i.e., 
                         : signal and one background). 
                         : 
                         : --- Performance optimisation:
                         : 
                         : Neural networks are stable and performing for a large variety of 
                         : linear and non-linear classification problems. However, in contrast
                         : to (e.g.) boosted decision trees, the user is advised to reduce the 
                         : number of input variables that have only little discrimination power. 
                         : 
                         : In the tests we have carried out so far, the MLP and ROOT networks
                         : (TMlpANN, interfaced via TMVA) performed equally well, with however
                         : a clear speed advantage for the MLP. The Clermont-Ferrand neural 
                         : net (CFMlpANN) exhibited worse classification performance in these
                         : tests, which is partly due to the slow convergence of its training
                         : (at least 10k training cycles are required to achieve approximately
                         : competitive results).
                         : 
                         : Overtraining: only the TMlpANN performs an explicit separation of the
                         : full training sample into independent training and validation samples.
                         : We have found that in most high-energy physics applications the 
                         : available degrees of freedom (training events) are sufficient to 
                         : constrain the weights of the relatively simple architectures required
                         : to achieve good performance. Hence no overtraining should occur, and 
                         : the use of validation samples would only reduce the available training
                         : information. However, if the performance on the training sample is 
                         : found to be significantly better than the one found with the inde-
                         : pendent test sample, caution is needed. The results for these samples 
                         : are printed to standard output at the end of each training job.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : The hidden layer architecture for all ANNs is defined by the option
                         : "HiddenLayers=N+1,N,...", where here the first hidden layer has N+1
                         : neurons and the second N neurons (and so on), and where N is the number  
                         : of input variables. Excessive numbers of hidden layers should be avoided,
                         : in favour of more neurons in the first hidden layer.
                         : 
                         : The number of cycles should be above 500. As said, if the number of
                         : adjustable weights is small compared to the training sample size,
                         : using a large number of training samples should not lead to overtraining.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
                         : Preparing the Decorrelation transformation...
<HEADER> TFHandler_MLP_3          :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:     0.81137      1.0000   [     -2.5839      13.337 ]
                         :     l1Pt_2:     0.77077      1.0000   [     -5.9308      17.032 ]
                         : l1DeltaEta:    0.041857      1.0000   [     -2.6652      3.2949 ]
                         : l1DeltaPhi:    0.036193      1.0000   [     -2.1489      2.1493 ]
                         :     l1Mass:     0.64012      1.0000   [   -0.043278      15.383 ]
                         : ---------------------------------------------------------------------
                         : Training Network
                         : 
                         : Inaccurate progress timing for MLP... 
                         : Elapsed time for training with 17176 events: 8.16 sec         
<HEADER> MLP_3                    : [dataset] : Evaluation of MLP_3 on training sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 0.0326 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_MLP_3.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_MLP_3.class.C
                         : Write special histos to file: TMVA_output.root:/dataset/Method_MLP_3/MLP_3
<HEADER> Factory                  : Training finished
                         : 
<HEADER> Factory                  : Train method: DNN for Classification
                         : 
<HEADER> TFHandler_DNN            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    0.021833     0.99882   [     -3.2357      5.4200 ]
                         :     l1Pt_2:   -0.012797      1.0083   [     -5.1237      5.7307 ]
                         : l1DeltaEta:  -0.0092430     0.92525   [     -5.2663      5.7307 ]
                         : l1DeltaPhi:  -0.0038107     0.99734   [     -3.5687      5.7307 ]
                         :     l1Mass:    0.019930      1.0026   [     -5.7307      5.7307 ]
                         : ---------------------------------------------------------------------
                         : Start of neural network training on CPU.
                         : 
                         : Training phase 1 of 1:
                         :      Epoch |   Train Err.  Test  Err.     GFLOP/s Conv. Steps
                         : --------------------------------------------------------------
                         :          1 |     0.891769    0.968643     3.58065           0
                         :          2 |     0.861984    0.941228     3.80983           0
                         :          3 |     0.850167    0.930484     3.90428           0
                         :          4 |     0.842635    0.926613     3.60648           0
                         :          5 |     0.841316    0.923616     3.75575           0
                         :          6 |     0.839834    0.922348     3.92202           0
                         :          7 |     0.837303    0.921816     3.94558           1
                         :          8 |     0.833799    0.921011     3.93391           0
                         :          9 |     0.834591     0.91928     4.03782           0
                         :         10 |     0.833661    0.917917     3.90604           0
                         :         11 |     0.832512    0.916834     3.72342           0
                         :         12 |     0.828722    0.916098     3.93772           1
                         :         13 |     0.830088    0.914787     3.97784           0
                         :         14 |      0.82922    0.914006     4.00658           1
                         :         15 |     0.826554    0.912161      3.8913           0
                         :         16 |     0.825194    0.911893     3.64852           1
                         :         17 |      0.82512       0.911     3.79967           0
                         :         18 |     0.823807    0.909278     3.75387           0
                         :         19 |     0.822209    0.907239     3.78116           0
                         :         20 |     0.820929    0.907724     2.50494           1
                         :         21 |       0.8199    0.905705     3.15382           0
                         :         22 |     0.818768    0.903659     3.25759           0
                         :         23 |     0.817139    0.902595     3.60062           0
                         :         24 |     0.812554     0.90083     3.78357           0
                         :         25 |     0.813854    0.899022     3.89881           0
                         :         26 |     0.812169    0.898887     3.58863           1
                         :         27 |     0.811441    0.898793     3.94472           2
                         :         28 |     0.809831     0.89628     3.78503           0
                         :         29 |      0.80741    0.893828     3.99451           0
                         :         30 |     0.806138    0.894391     3.84388           1
                         :         31 |     0.804113    0.893306     3.98288           2
                         :         32 |     0.803023    0.889608     3.91827           0
                         :         33 |      0.80199    0.888824     3.95961           1
                         :         34 |      0.79969    0.886099     3.91243           0
                         :         35 |     0.797422    0.885757      3.7738           1
                         :         36 |     0.795466     0.88677     3.86358           2
                         :         37 |      0.79515    0.885769     3.91337           3
                         :         38 |     0.794049    0.881477     3.81014           0
                         :         39 |     0.793618    0.882835     3.99217           1
                         :         40 |     0.793133    0.883911     3.97767           2
                         :         41 |        0.791    0.881322     3.95539           3
                         :         42 |     0.788325    0.881074      3.8145           4
                         :         43 |     0.790327    0.878704     3.97281           0
                         :         44 |     0.787867    0.879195     3.74032           1
                         :         45 |     0.786924    0.879612     3.71108           2
                         :         46 |     0.788394     0.87988     3.81208           3
                         :         47 |      0.78756    0.876002     3.90173           0
                         :         48 |     0.785489    0.883849     3.96915           1
                         :         49 |      0.78424    0.878655      3.7607           2
                         :         50 |     0.786322    0.879727     3.93186           3
                         :         51 |     0.782917    0.878137     3.91849           4
                         :         52 |      0.78331    0.882481     3.91922           5
                         :         53 |     0.781657    0.876636     3.76273           6
                         :         54 |     0.782042    0.875026     3.98403           0
                         :         55 |     0.783705    0.882319     4.11755           1
                         :         56 |      0.78074    0.879859     3.73248           2
                         :         57 |     0.783828    0.879522     3.51593           3
                         :         58 |      0.77959    0.877103     3.97958           4
                         :         59 |     0.777939    0.878424     3.96561           5
                         :         60 |     0.780797    0.881087     3.85566           6
                         :         61 |     0.780269    0.878643     3.43212           7
                         :         62 |     0.779419    0.877029     3.72889           8
                         :         63 |     0.779892     0.87892     3.74983           9
                         :         64 |     0.777819    0.874674     3.75504          10
                         : 
                         : Elapsed time for training with 17176 events: 12.4 sec         
<HEADER> DNN                      : [dataset] : Evaluation of DNN on training sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 0.444 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_DNN.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_DNN.class.C
<HEADER> Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
<HEADER> BDT                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : l1Pt_1     : 2.310e-01
                         :    2 : l1DeltaPhi : 2.051e-01
                         :    3 : l1DeltaEta : 2.019e-01
                         :    4 : l1Mass     : 1.829e-01
                         :    5 : l1Pt_2     : 1.791e-01
                         : --------------------------------------------
<HEADER> MLP_1                    : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Importance
                         : -----------------------------------
                         :    1 : l1Pt_1     : 2.561e+02
                         :    2 : l1Pt_2     : 9.281e+01
                         :    3 : l1Mass     : 4.781e+01
                         :    4 : l1DeltaPhi : 4.299e+00
                         :    5 : l1DeltaEta : 4.097e-01
                         : -----------------------------------
<HEADER> MLP_2                    : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Importance
                         : -----------------------------------
                         :    1 : l1Pt_1     : 2.681e+02
                         :    2 : l1Pt_2     : 1.439e+02
                         :    3 : l1Mass     : 1.310e+02
                         :    4 : l1DeltaEta : 7.360e+00
                         :    5 : l1DeltaPhi : 6.399e+00
                         : -----------------------------------
<HEADER> MLP_3                    : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Importance
                         : -----------------------------------
                         :    1 : l1Mass     : 9.503e+01
                         :    2 : l1Pt_1     : 9.150e+01
                         :    3 : l1Pt_2     : 4.257e+01
                         :    4 : l1DeltaEta : 3.889e+01
                         :    5 : l1DeltaPhi : 1.277e+01
                         : -----------------------------------
<HEADER> DNN                      : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Importance
                         : -----------------------------------
                         :    1 : l1Pt_1     : 1.000e+00
                         :    2 : l1Pt_2     : 1.000e+00
                         :    3 : l1DeltaEta : 1.000e+00
                         :    4 : l1DeltaPhi : 1.000e+00
                         :    5 : l1Mass     : 1.000e+00
                         : -----------------------------------
<HEADER> Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
<HEADER> MLP_1                    : Building Network. 
                         : Initializing weights
<HEADER> MLP_2                    : Building Network. 
                         : Initializing weights
<HEADER> MLP_3                    : Building Network. 
                         : Initializing weights
<HEADER> Factory                  : Test all methods
<HEADER> Factory                  : Test method: BDT for Classification performance
                         : 
<HEADER> BDT                      : [dataset] : Evaluation of BDT on testing sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 1.04 sec       
<HEADER> Factory                  : Test method: MLP_1 for Classification performance
                         : 
<HEADER> MLP_1                    : [dataset] : Evaluation of MLP_1 on testing sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 0.0341 sec       
<HEADER> Factory                  : Test method: MLP_2 for Classification performance
                         : 
<HEADER> MLP_2                    : [dataset] : Evaluation of MLP_2 on testing sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 0.0339 sec       
<HEADER> Factory                  : Test method: MLP_3 for Classification performance
                         : 
<HEADER> MLP_3                    : [dataset] : Evaluation of MLP_3 on testing sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 0.0316 sec       
<HEADER> Factory                  : Test method: DNN for Classification performance
                         : 
<HEADER> DNN                      : [dataset] : Evaluation of DNN on testing sample (17176 events)
                         : Elapsed time for evaluation of 17176 events: 0.44 sec       
<HEADER> Factory                  : Evaluate all methods
<HEADER> Factory                  : Evaluate classifier: BDT
                         : 
<HEADER> BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
<HEADER> TFHandler_BDT            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:      75.966      55.076   [      5.5000      511.50 ]
                         :     l1Pt_2:      50.748      37.934   [      5.5000      511.50 ]
                         : l1DeltaEta:    0.013063      2.9079   [     -8.7600      9.3000 ]
                         : l1DeltaPhi:   0.0098897      2.9699   [     -6.1912      6.1912 ]
                         :     l1Mass:      305.51      397.27   [      7.2438      6744.3 ]
                         : ---------------------------------------------------------------------
<HEADER> Factory                  : Evaluate classifier: MLP_1
                         : 
<HEADER> TFHandler_MLP_1          :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    -0.72148     0.21769   [     -1.0000      1.0000 ]
                         :     l1Pt_2:    -0.82115     0.14994   [     -1.0000      1.0000 ]
                         : l1DeltaEta:   -0.019057     0.33195   [     -1.0205      1.0411 ]
                         : l1DeltaPhi:   0.0087008     0.48310   [     -1.0000      1.0142 ]
                         :     l1Mass:    -0.88630     0.14785   [    -0.99730      1.5100 ]
                         : ---------------------------------------------------------------------
<HEADER> MLP_1                    : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
<HEADER> TFHandler_MLP_1          :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    -0.72148     0.21769   [     -1.0000      1.0000 ]
                         :     l1Pt_2:    -0.82115     0.14994   [     -1.0000      1.0000 ]
                         : l1DeltaEta:   -0.019057     0.33195   [     -1.0205      1.0411 ]
                         : l1DeltaPhi:   0.0087008     0.48310   [     -1.0000      1.0142 ]
                         :     l1Mass:    -0.88630     0.14785   [    -0.99730      1.5100 ]
                         : ---------------------------------------------------------------------
<HEADER> Factory                  : Evaluate classifier: MLP_2
                         : 
<HEADER> TFHandler_MLP_2          :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    -0.72148     0.21769   [     -1.0000      1.0000 ]
                         :     l1Pt_2:    -0.82115     0.14994   [     -1.0000      1.0000 ]
                         : l1DeltaEta:   -0.019057     0.33195   [     -1.0205      1.0411 ]
                         : l1DeltaPhi:   0.0087008     0.48310   [     -1.0000      1.0142 ]
                         :     l1Mass:    -0.88630     0.14785   [    -0.99730      1.5100 ]
                         : ---------------------------------------------------------------------
<HEADER> MLP_2                    : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
<HEADER> TFHandler_MLP_2          :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    -0.72148     0.21769   [     -1.0000      1.0000 ]
                         :     l1Pt_2:    -0.82115     0.14994   [     -1.0000      1.0000 ]
                         : l1DeltaEta:   -0.019057     0.33195   [     -1.0205      1.0411 ]
                         : l1DeltaPhi:   0.0087008     0.48310   [     -1.0000      1.0142 ]
                         :     l1Mass:    -0.88630     0.14785   [    -0.99730      1.5100 ]
                         : ---------------------------------------------------------------------
<HEADER> Factory                  : Evaluate classifier: MLP_3
                         : 
<HEADER> TFHandler_MLP_3          :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:      1.1495      1.1408   [     -3.3804      12.500 ]
                         :     l1Pt_2:     0.93383      1.1775   [     -5.8742      15.911 ]
                         : l1DeltaEta:    0.037567     0.95894   [     -2.7135      3.3142 ]
                         : l1DeltaPhi:    0.021025      1.0287   [     -2.1349      2.1768 ]
                         :     l1Mass:     0.78387      1.1217   [   -0.039854      19.318 ]
                         : ---------------------------------------------------------------------
<HEADER> MLP_3                    : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
<HEADER> TFHandler_MLP_3          :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:      1.1495      1.1408   [     -3.3804      12.500 ]
                         :     l1Pt_2:     0.93383      1.1775   [     -5.8742      15.911 ]
                         : l1DeltaEta:    0.037567     0.95894   [     -2.7135      3.3142 ]
                         : l1DeltaPhi:    0.021025      1.0287   [     -2.1349      2.1768 ]
                         :     l1Mass:     0.78387      1.1217   [   -0.039854      19.318 ]
                         : ---------------------------------------------------------------------
<HEADER> Factory                  : Evaluate classifier: DNN
                         : 
<HEADER> TFHandler_DNN            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:     0.49951     0.88370   [     -3.2357      5.4200 ]
                         :     l1Pt_2:     0.38019     0.92854   [     -5.1237      5.7307 ]
                         : l1DeltaEta:   -0.017031     0.87348   [     -5.7307      5.7307 ]
                         : l1DeltaPhi:   -0.023669      1.0237   [     -3.5687      5.7307 ]
                         :     l1Mass:     0.32793     0.87725   [     -3.0975      5.7307 ]
                         : ---------------------------------------------------------------------
<HEADER> DNN                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
<HEADER> TFHandler_DNN            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:     0.49951     0.88370   [     -3.2357      5.4200 ]
                         :     l1Pt_2:     0.38019     0.92854   [     -5.1237      5.7307 ]
                         : l1DeltaEta:   -0.017031     0.87348   [     -5.7307      5.7307 ]
                         : l1DeltaPhi:   -0.023669      1.0237   [     -3.5687      5.7307 ]
                         :     l1Mass:     0.32793     0.87725   [     -3.0975      5.7307 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       BDT            : 0.868
                         : dataset       DNN            : 0.867
                         : dataset       MLP_2          : 0.862
                         : dataset       MLP_1          : 0.861
                         : dataset       MLP_3          : 0.861
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              BDT            : 0.259 (0.439)       0.583 (0.737)      0.859 (0.888)
                         : dataset              DNN            : 0.231 (0.244)       0.599 (0.604)      0.847 (0.858)
                         : dataset              MLP_2          : 0.207 (0.251)       0.586 (0.606)      0.848 (0.858)
                         : dataset              MLP_1          : 0.198 (0.224)       0.578 (0.581)      0.856 (0.858)
                         : dataset              MLP_3          : 0.227 (0.261)       0.576 (0.619)      0.848 (0.863)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
<HEADER> Dataset:dataset          : Created tree 'TestTree' with 17176 events
                         : 
<HEADER> Dataset:dataset          : Created tree 'TrainTree' with 17176 events
                         : 
<HEADER> Factory                  : Thank you for using TMVA!
                         : For citation information, please visit: http://tmva.sf.net/citeTMVA.html
